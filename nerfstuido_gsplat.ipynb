{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/softmurata/NeRFML/blob/main/nerfstuido_gsplat.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "NeRFSTudio"
      ],
      "metadata": {
        "id": "VuZaSNJ2Tlv3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D46MmUQlRpkM"
      },
      "outputs": [],
      "source": [
        "!pip install -q git+https://github.com/nerfstudio-project/gsplat.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bERTha28R3l7"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/nerfstudio-project/gsplat.git\n",
        "%cd /content/gsplat\n",
        "!pip install -r examples/requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cmrX9DCtSddW"
      },
      "outputs": [],
      "source": [
        "!wget https://cdn-ak.f.st-hatena.com/images/fotolife/u/unlit/20221006/20221006100839.png -O /content/shovel.png"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uug2wc68SAiX"
      },
      "outputs": [],
      "source": [
        "%cd /content/gsplat\n",
        "!python examples/simple_trainer.py --img_path /content/shovel.png"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "PhwJZHgmS3O4"
      },
      "outputs": [],
      "source": [
        "import IPython\n",
        "\n",
        "\n",
        "out_filename = '/content/gsplat/renders/training.gif'\n",
        "IPython.display.Image(out_filename, format='png')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Camenderu"
      ],
      "metadata": {
        "id": "1Q5wSUz_TnSY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content\n",
        "!git clone --recursive https://github.com/camenduru/gaussian-splatting\n",
        "!pip install -q plyfile\n",
        "\n",
        "%cd /content/gaussian-splatting\n",
        "!pip install -q /content/gaussian-splatting/submodules/diff-gaussian-rasterization\n",
        "!pip install -q /content/gaussian-splatting/submodules/simple-knn\n",
        "\n",
        "!wget https://huggingface.co/camenduru/gaussian-splatting/resolve/main/tandt_db.zip\n",
        "!unzip tandt_db.zip\n",
        "\n",
        "!python train.py -s /content/gaussian-splatting/tandt/train"
      ],
      "metadata": {
        "id": "4myv2pg2Tomt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://huggingface.co/camenduru/gaussian-splatting/resolve/main/GaussianViewTest.zip\n",
        "!unzip GaussianViewTest.zip"
      ],
      "metadata": {
        "id": "VMC-rPEmTuJp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python render.py -m /content/gaussian-splatting/output/764f1c43-a"
      ],
      "metadata": {
        "id": "qnpIELuHaKlW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ffmpeg -framerate 3 -i /content/gaussian-splatting/output/764f1c43-a/train/ours_30000/renders/%05d.png -vf \"pad=ceil(iw/2)*2:ceil(ih/2)*2\" -c:v libx264 -r 3 -pix_fmt yuv420p /content/renders.mp4\n",
        "!ffmpeg -framerate 3 -i /content/gaussian-splatting/output/764f1c43-a/train/ours_30000/gt/%05d.png -vf \"pad=ceil(iw/2)*2:ceil(ih/2)*2\" -c:v libx264 -r 3 -pix_fmt yuv420p /content/gt.mp4 -y"
      ],
      "metadata": {
        "id": "WE_hwh4RZ-6f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "\n",
        "mp4 = open('/content/renders.mp4', 'rb').read()\n",
        "data_url = 'data:video/mp4;base64,' + b64encode(mp4).decode()\n",
        "HTML(f\"\"\"\n",
        "<video width=\"100%\" height=\"100%\" controls>\n",
        "      <source src=\"{data_url}\" type=\"video/mp4\">\n",
        "</video>\"\"\")"
      ],
      "metadata": {
        "id": "4Yr9IDEefLN3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CLIP Guided Gaussisn Splating"
      ],
      "metadata": {
        "id": "p0oLHSyPUQxG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import locale\n",
        "locale.getpreferredencoding = lambda: \"UTF-8\"\n",
        "\n",
        "%cd /content\n",
        "!git clone --recursive https://github.com/camenduru/gaussian-splatting\n",
        "!pip install -q plyfile\n",
        "\n",
        "%cd /content/gaussian-splatting\n",
        "!pip install -q https://huggingface.co/camenduru/gaussian-splatting/resolve/main/diff_gaussian_rasterization-0.0.0-cp310-cp310-linux_x86_64.whl\n",
        "!pip install -q https://huggingface.co/camenduru/gaussian-splatting/resolve/main/simple_knn-0.0.0-cp310-cp310-linux_x86_64.whl\n",
        "\n",
        "!pip install git+https://github.com/facebookresearch/ImageBind\n",
        "!pip install open_clip_torch celluloid matplotlib tqdm"
      ],
      "metadata": {
        "id": "3lXMPvS3VH2M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from random import randint\n",
        "from utils.loss_utils import l1_loss, ssim\n",
        "from gaussian_renderer import render, network_gui\n",
        "import sys\n",
        "from scene import Scene, GaussianModel\n",
        "from scene.cameras import Camera\n",
        "from scene.gaussian_model import BasicPointCloud\n",
        "from utils.sh_utils import SH2RGB\n",
        "from utils.general_utils import safe_state\n",
        "import uuid\n",
        "from tqdm import tqdm\n",
        "from utils.image_utils import psnr\n",
        "from argparse import ArgumentParser, Namespace\n",
        "from arguments import ModelParams, PipelineParams, OptimizationParams\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import open_clip\n",
        "from torchvision.transforms import Normalize\n",
        "\n",
        "oclip = 'ViT-B-32'\n",
        "model, _, preprocess = open_clip.create_model_and_transforms(oclip, pretrained='laion2b_s34b_b79k')\n",
        "\n",
        "model.requires_grad_(False).cuda().half()\n",
        "tokenizer = open_clip.get_tokenizer(oclip)\n",
        "\n",
        "\n",
        "clippp = Normalize(mean=model.visual.image_mean, std=model.visual.image_std)\n",
        "model = torch.jit.script(model)\n",
        "\n",
        "num_pts = 100\n",
        "print(f\"Generating random point cloud ({num_pts})...\")\n",
        "\n",
        "# We create random points inside the bounds of the synthetic Blender scenes\n",
        "camera_extent = 5.0\n",
        "xyz = np.random.normal(size=(num_pts, 3))\n",
        "xyz = 1.3 * xyz / np.linalg.norm(xyz, axis=-1, keepdims=True)\n",
        "shs = np.random.random((num_pts, 3)) / 255.0\n",
        "pcd = BasicPointCloud(points=xyz, colors=SH2RGB(shs), normals=np.zeros((num_pts, 3)))\n"
      ],
      "metadata": {
        "id": "RC84Uuh3VV8G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def random_crops(img, n, resize_to=224, min_size=0.5, max_size=1.0):\n",
        "    sizes = torch.rand(n) * (max_size - min_size) + min_size\n",
        "    top_left = torch.rand(n, 2) * (1.0 - sizes[:, None])\n",
        "    transforms = torch.eye(2).unsqueeze(0).repeat(n, 1, 1) * sizes[:, None, None]\n",
        "    transforms = torch.cat([transforms, top_left[:, :, None]], dim=-1)\n",
        "    grids = torch.nn.functional.affine_grid(transforms, [n, img.shape[1], resize_to, resize_to], align_corners=True).to(img.device)\n",
        "    return torch.nn.functional.grid_sample(img.repeat(n, 1, 1, 1), grids, align_corners=True)\n",
        "\n",
        "\n",
        "from celluloid import Camera as PltCamera\n",
        "from math import floor\n",
        "try:\n",
        "    from torch.utils.tensorboard import SummaryWriter\n",
        "    TENSORBOARD_FOUND = True\n",
        "except ImportError:\n",
        "    TENSORBOARD_FOUND = False\n",
        "\n",
        "def rot2d(angle):\n",
        "    return torch.tensor([\n",
        "        [torch.cos(angle), torch.sin(angle), torch.tensor(0)],\n",
        "       [-torch.sin(angle), torch.cos(angle), torch.tensor(0)],\n",
        "        [torch.tensor(0), torch.tensor(0), torch.tensor(1)]\n",
        "    ])\n",
        "\n",
        "def normalize(x):\n",
        "    return x / x.norm(dim=-1, keepdim=True)\n",
        "def look_at(eye, at, up):\n",
        "    z = normalize(eye - at)\n",
        "    x = normalize(torch.linalg.cross(up, z))\n",
        "    y = normalize(torch.linalg.cross(z, x))\n",
        "    rot = torch.stack([x, y, z]).T\n",
        "    trans = torch.tensor([x @ eye, y @ eye, z @ eye])\n",
        "    return rot, trans\n",
        "\n",
        "\n",
        "def show(tensor):\n",
        "    tensor = tensor.detach().permute(1, 2, 0)\n",
        "    plt.imshow(tensor.cpu().numpy())\n",
        "\n",
        "def training(prompt, dataset, opt, pipe, testing_iterations, saving_iterations, checkpoint_iterations, checkpoint, debug_from):\n",
        "    first_iter = 0\n",
        "    gaussians = GaussianModel(dataset.sh_degree)\n",
        "    # scene = Scene(dataset, gaussians)\n",
        "    gaussians.create_from_pcd(pcd, camera_extent)\n",
        "    gaussians.training_setup(opt)\n",
        "    if checkpoint:\n",
        "        (model_params, first_iter) = torch.load(checkpoint)\n",
        "        gaussians.restore(model_params, opt)\n",
        "\n",
        "    bg_color = [0, 0, 0]\n",
        "    background = torch.tensor(bg_color, dtype=torch.float32, device=\"cuda\")\n",
        "\n",
        "    iter_start = torch.cuda.Event(enable_timing = True)\n",
        "    iter_end = torch.cuda.Event(enable_timing = True)\n",
        "\n",
        "    viewpoint_stack = None\n",
        "    ema_loss_for_log = 0.0\n",
        "    progress_bar = tqdm(range(first_iter, opt.iterations), desc=\"Training progress\")\n",
        "    first_iter += 1\n",
        "    # dbgfig = plt.figure()\n",
        "    fig = plt.figure()\n",
        "    camera = PltCamera(fig)\n",
        "\n",
        "    for iteration in range(first_iter, opt.iterations + 1):\n",
        "\n",
        "        iter_start.record()\n",
        "\n",
        "        gaussians.update_learning_rate(iteration)\n",
        "\n",
        "        # Every 1000 its we increase the levels of SH up to a maximum degree\n",
        "        if iteration % 1000 == 0:\n",
        "            gaussians.oneupSHdegree()\n",
        "\n",
        "        # Pick a random Camera\n",
        "        # if not viewpoint_stack:\n",
        "        #    viewpoint_stack = scene.getTrainCameras().copy()\n",
        "        # viewpoint_cam = viewpoint_stack.pop(randint(0, len(viewpoint_stack)-1))\n",
        "        rand_angle = torch.rand(1) * 3.14159 * 2.0\n",
        "        rand_pos = camera_extent * torch.tensor([rand_angle.cos(), 0.0, rand_angle.sin()])\n",
        "        rand_pos[1] = 0.2 + (torch.rand(1) * 2 - 1) * 0.3\n",
        "        dist, direc = torch.linalg.norm(rand_pos), normalize(rand_pos)\n",
        "        rand_pos = direc * camera_extent\n",
        "\n",
        "\n",
        "        # if (iteration % 10) == 0:\n",
        "        #     rand_pos = torch.tensor([0.0, 0.0, camera_extent])\n",
        "        #     rand_pos = rand_pos + torch.tensor([torch.tensor(3.14159 * 4.0 * iteration / opt.iterations).cos(), torch.tensor(3.14159 * 4.0 * iteration / opt.iterations).sin(), 0.0])\n",
        "\n",
        "        rot, trans = look_at(rand_pos, torch.tensor([0.0, 0.0, 0.0]), torch.tensor([0.0, 1.0, 0.0]))\n",
        "\n",
        "        train_res = floor(512 * (iteration / opt.iterations))\n",
        "        train_res = 32 * (1 + train_res // 32)\n",
        "        viewpoint_cam = Camera(\n",
        "            colmap_id=0,\n",
        "            R=rot.numpy(), #rand_angle.numpy(),\n",
        "            T=trans.numpy(), #torch.zeros((3,)).numpy(),\n",
        "            FoVx=90.0,\n",
        "            FoVy=90.0,\n",
        "            image=torch.zeros((3, train_res, train_res)),\n",
        "            gt_alpha_mask=torch.ones((train_res, train_res)),\n",
        "            image_name=\"test\",\n",
        "            uid=0,\n",
        "        )\n",
        "        # Render\n",
        "        if (iteration - 1) == debug_from:\n",
        "            pipe.debug = True\n",
        "        render_pkg = render(viewpoint_cam, gaussians, pipe, bg_color=torch.rand(3).cuda())\n",
        "        image, viewspace_point_tensor, visibility_filter, radii = render_pkg[\"render\"], render_pkg[\"viewspace_points\"], render_pkg[\"visibility_filter\"], render_pkg[\"radii\"]\n",
        "\n",
        "        # Loss\n",
        "\n",
        "        views = [\"front view\", \"left side view\", \"back view\", \"right side view\"]\n",
        "        qangle = floor(4 * rand_angle / (2 * 3.14159))\n",
        "        view = views[qangle]\n",
        "\n",
        "        prompt = prompt.format(view)\n",
        "        #text = tokenizer([\"a photo of a beautiful twink statue, not noisy, not rainbow, cute, accurate anatomy, black background, greeco-roman statue\"]).cuda()\n",
        "        #text = tokenizer([f\"a photo of a beautiful twink statue, {view}, not noisy, not rainbow, cute, accurate anatomy, black background, greeco-roman statue\"]).cuda()\n",
        "        #text = tokenizer([\"a 3d model of a cyber-sigilist statue, sumerian god, celestialpunk, beautiful, monochrome shiny, gloss\"]).cuda()\n",
        "        text = tokenizer([prompt]).cuda()\n",
        "        #text = tokenizer([f\"a 3d model of an astronaut riding a horse, 3d asset, high quality, not noisy, beautiful, black background\"]).cuda()\n",
        "        #text = tokenizer([\"a 3d model of the Mona Lisa, 3d asset, high quality, not noisy, beautiful, black background\"]).cuda()\n",
        "        #text = tokenizer([f\"a 3d model of a tabby cat, {view}, 3d asset, high quality, not noisy, beautiful, black background\"]).cuda()\n",
        "        text_vec = model.encode_text(text).float()\n",
        "        text_vec = text_vec / text_vec.norm(dim=-1, keepdim=True)\n",
        "\n",
        "        crops = random_crops(image.unsqueeze(0), 32, min_size=0.7, max_size=0.9)\n",
        "        img_vec = model.encode_image(clippp(crops).half()).float()\n",
        "        img_vec = img_vec / img_vec.norm(dim=-1, keepdim=True)\n",
        "\n",
        "        sim = img_vec @ text_vec.T\n",
        "        clip_loss = -sim.mean()\n",
        "        # self_sim = -(img_vec @ img_vec.T).mean()\n",
        "        # loss = (1.0 - opt.lambda_dssim) * Ll1 + opt.lambda_dssim * (1.0 - ssim(image, gt_image))\n",
        "        loss = clip_loss\n",
        "        loss.backward()\n",
        "\n",
        "        iter_end.record()\n",
        "\n",
        "        if ((iteration % 10) == 0 or iteration == opt.iterations) and iteration > 700:\n",
        "            rand_pos = torch.tensor([0.0, 0.0, camera_extent])\n",
        "            angle = 3.14159 * 2.0 * iteration / opt.iterations\n",
        "            rand_pos = camera_extent * torch.tensor([torch.tensor(angle).cos(), 0.0, torch.tensor(angle).sin()])\n",
        "\n",
        "            rot, trans = look_at(rand_pos, torch.tensor([0.0, 0.0, 0.0]), torch.tensor([0.0, 1.0, 0.0]))\n",
        "\n",
        "            dbg_cam = Camera(\n",
        "                colmap_id=0,\n",
        "                R=rot.numpy(), #rand_angle.numpy(),\n",
        "                T=trans.numpy(), #torch.zeros((3,)).numpy(),\n",
        "                FoVx=90.0,\n",
        "                FoVy=90.0,\n",
        "                image=torch.zeros((3, 512, 512)),\n",
        "                gt_alpha_mask=torch.ones((512, 512)),\n",
        "                image_name=\"test\",\n",
        "                uid=0,\n",
        "            )\n",
        "            image = render(dbg_cam, gaussians, pipe, background)[\"render\"]\n",
        "\n",
        "            show(image)\n",
        "            camera.snap()\n",
        "\n",
        "        if iteration == opt.iterations:\n",
        "            return camera.animate(blit = False, interval = 50), gaussians\n",
        "\n",
        "\n",
        "        with torch.no_grad():\n",
        "            # Progress bar\n",
        "            ema_loss_for_log = 0.4 * loss.item() + 0.6 * ema_loss_for_log\n",
        "            if iteration % 10 == 0:\n",
        "                progress_bar.set_postfix({\"Loss\": f\"{ema_loss_for_log:.{7}f}\"})\n",
        "                progress_bar.update(10)\n",
        "            if iteration == opt.iterations:\n",
        "                progress_bar.close()\n",
        "\n",
        "            # Log and save\n",
        "            # training_report(tb_writer, iteration, Ll1, loss, l1_loss, iter_start.elapsed_time(iter_end), testing_iterations, scene, render, (pipe, background))\n",
        "            if (iteration in saving_iterations):\n",
        "                print(\"\\n[ITER {}] Saving Gaussians\".format(iteration))\n",
        "                scene.save(iteration)\n",
        "\n",
        "            # Densification\n",
        "            if iteration < opt.densify_until_iter:\n",
        "                # Keep track of max radii in image-space for pruning\n",
        "                gaussians.max_radii2D[visibility_filter] = torch.max(gaussians.max_radii2D[visibility_filter], radii[visibility_filter])\n",
        "\n",
        "                gaussians.add_densification_stats(viewspace_point_tensor, visibility_filter)\n",
        "\n",
        "                densify = iteration % opt.densification_interval == 0\n",
        "                if iteration > opt.densify_from_iter and densify:\n",
        "                    size_threshold = 20 if iteration > opt.opacity_reset_interval else None\n",
        "                    gaussians.densify_and_prune(opt.densify_grad_threshold, 0.005, camera_extent, size_threshold)\n",
        "\n",
        "                if iteration % opt.opacity_reset_interval == 0 or (dataset.white_background and iteration == opt.densify_from_iter):\n",
        "                    gaussians.reset_opacity()\n",
        "\n",
        "            # Optimizer step\n",
        "            if iteration < opt.iterations and (iteration % 1) == 0:\n",
        "                gaussians.optimizer.step()\n",
        "                gaussians.optimizer.zero_grad(set_to_none = True)\n",
        "\n",
        "            if (iteration in checkpoint_iterations):\n",
        "                print(\"\\n[ITER {}] Saving Checkpoint\".format(iteration))\n",
        "                torch.save((gaussians.capture(), iteration), scene.model_path + \"/chkpnt\" + str(iteration) + \".pth\")"
      ],
      "metadata": {
        "id": "L_EuSv2HVvx8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm import tqdm\n",
        "try:\n",
        "    tqdm._instances.clear()\n",
        "except:\n",
        "    pass"
      ],
      "metadata": {
        "id": "tdJ-roy6V6QI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run\n",
        "from IPython.core.display import HTML\n",
        "\n",
        "prompt = \"a 3d model of Van Gogh's Sunflowers, 3d asset, high quality, not noisy, beautiful, black background\"\n",
        "# Put a {} in your prompt to have view depedent prompting\n",
        "# i.e \"a cat, {}\" -> \"a cat, front view\", \"a cat, side view\" etc\n",
        "\n",
        "parser = ArgumentParser()\n",
        "model_params = ModelParams(parser)\n",
        "opt_params = OptimizationParams(parser)\n",
        "pp = PipelineParams(parser)\n",
        "args, _ = parser.parse_known_args()\n",
        "args.iterations = 2500\n",
        "args.position_lr_init = 1e-2\n",
        "args.position_lr_final = 1e-5\n",
        "args.position_lr_max_steps = args.iterations\n",
        "# args.opacity_reset_interval = 1000\n",
        "torch.manual_seed(2023)\n",
        "animation, gaussians = training(prompt, model_params.extract(args), opt_params.extract(args), pp.extract(args), [], [], [], None, -1)\n",
        "HTML(animation.to_html5_video())"
      ],
      "metadata": {
        "id": "TzmQUWb7V77K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gaussians.save_ply(\"../output.ply\")"
      ],
      "metadata": {
        "id": "lth9BWuvWBr8"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM6IHzfEpRfa+GNHI4+8Jtg",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}